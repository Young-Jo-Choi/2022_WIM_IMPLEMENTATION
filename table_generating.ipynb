{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x): \n",
    "    unique_list = list(np.unique(x))\n",
    "    if len(unique_list)==1:\n",
    "        return unique_list[0]\n",
    "    else:\n",
    "        return unique_list\n",
    "# standard = pd.read_excel('[MOA_CDM]variable_selection_by_methods.xlsx',engine='openpyxl',sheet_name='concept_set_by_methods')\n",
    "# standard = pd.read_csv('MOA_CDM_variable_selection_by_methods.csv')\n",
    "standard = pd.read_csv('selected_vars_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin\n",
    "def load_df_and_concept_id(outcome_name,method):\n",
    "    # 수정\n",
    "    importsql_output_dir = 'data/19000101/importsql/{}'.format(outcome_name)\n",
    "    \n",
    "    meas_df = pd.read_csv('{}/{}_meas_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "    drug_df = pd.read_csv('{}/{}_drug_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "    proc_df = pd.read_csv('{}/{}_proc_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "    cond_df = pd.read_csv('{}/{}_cond_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "    proc_df['concept_value'] = 1\n",
    "    cond_df['concept_value'] = 1\n",
    "    drug_df['concept_value'] = 1\n",
    "    \n",
    "    cond1 = standard['outcome_name']==outcome_name\n",
    "    cond2 = standard['method']==method\n",
    "    concept_ids_cond = standard.loc[cond1&cond2,'cond'].values[0]\n",
    "    concept_ids_drug = standard.loc[cond1&cond2,'drug'].values[0]\n",
    "    concept_ids_proc = standard.loc[cond1&cond2,'proc'].values[0]\n",
    "    concept_ids_meas = standard.loc[cond1&cond2,'meas'].values[0]\n",
    "    \n",
    "    concept_id_cond_list = list(eval(concept_ids_cond))\n",
    "    concept_id_drug_list = list(eval(concept_ids_drug))\n",
    "    concept_id_proc_list = list(eval(concept_ids_proc))\n",
    "    concept_id_meas_list = list(eval(concept_ids_meas))\n",
    "    return {'meas_df':meas_df,'drug_df':drug_df,'proc_df':proc_df,'cond_df':cond_df,\n",
    "           'concept_id_cond_list':concept_id_cond_list,'concept_id_drug_list':concept_id_drug_list,\n",
    "           'concept_id_proc_list':concept_id_proc_list,'concept_id_meas_list':concept_id_meas_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_and_concept_id2(outcome_name,method):\n",
    "    # 수정\n",
    "    importsql_output_dir = 'data/19000101/importsql/{}/all_domain_df.txt'.format(outcome_name)\n",
    "    df = pd.read_csv(importsql_output_dir)\n",
    "#     path = f'../Hospitals/{insti}/220927/importsql/{outcome_name}/all_domain_df.txt'\n",
    "#     df = pd.read_csv(path) \n",
    "    \n",
    "    meas_df = df.query('concept_domain==\"meas\"')\n",
    "    drug_df = df.query('concept_domain==\"drug\"')\n",
    "    proc_df = df.query('concept_domain==\"proc\"')\n",
    "    cond_df = df.query('concept_domain==\"cond\"')\n",
    "    \n",
    "    proc_df.loc[:,'concept_value'] = 1\n",
    "    cond_df.loc[:,'concept_value'] = 1\n",
    "    drug_df.loc[:,'concept_value'] = 1\n",
    "    \n",
    "    cond1 = standard['outcome_name']==outcome_name\n",
    "    cond2 = standard['method']==method\n",
    "    concept_ids_cond = standard.loc[cond1&cond2,'cond'].values[0]\n",
    "    concept_ids_drug = standard.loc[cond1&cond2,'drug'].values[0]\n",
    "    concept_ids_proc = standard.loc[cond1&cond2,'proc'].values[0]\n",
    "    concept_ids_meas = standard.loc[cond1&cond2,'meas'].values[0]\n",
    "    \n",
    "    concept_id_cond_list = list(eval(concept_ids_cond))\n",
    "    concept_id_drug_list = list(eval(concept_ids_drug))\n",
    "    concept_id_proc_list = list(eval(concept_ids_proc))\n",
    "    concept_id_meas_list = list(eval(concept_ids_meas))\n",
    "    return {'meas_df':meas_df,'drug_df':drug_df,'proc_df':proc_df,'cond_df':cond_df,\n",
    "           'concept_id_cond_list':concept_id_cond_list,'concept_id_drug_list':concept_id_drug_list,\n",
    "           'concept_id_proc_list':concept_id_proc_list,'concept_id_meas_list':concept_id_meas_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept_id_dict = dict(zip(df['concept_id'],df['concept_name']))\n",
    "def pivot_and_concat(df, concept_id_list):\n",
    "    timedelta = pd.to_datetime(df['cohort_start_date']) - pd.to_datetime(df['concept_date'])\n",
    "    cond1 = timedelta.dt.days >= 0\n",
    "    cond2 = timedelta.dt.days <= 30\n",
    "    df_1month = df[cond1&cond2]\n",
    "\n",
    "    df_1month_grouped = df_1month.groupby(['person_id','concept_id']).agg({'cohort_start_date':identity,'age':identity,\n",
    "                                                                           'sex':identity,'label':identity,'concept_domain':identity,'concept_value':'mean'})\n",
    "\n",
    "    no_pivoted = df_1month_grouped.reset_index(level=0).drop(['concept_value'],axis=1).drop_duplicates().set_index('person_id')\n",
    "    pivoted = df_1month_grouped.reset_index().pivot(index='person_id', columns = 'concept_id',values='concept_value')\n",
    "    # 수정(할 필요는 딱히 없을듯)\n",
    "    pivoted_selected_vars = pivoted[np.intersect1d(pivoted.columns,list(map(int,concept_id_list)))]\n",
    "\n",
    "    df_pivoted = pd.concat([no_pivoted, pivoted_selected_vars],axis=1)\n",
    "    df_pivoted = df_pivoted.reset_index()\n",
    "    return df_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_concat(df1, df2, df3, df4, on=['person_id','cohort_start_date','age','sex','label']):\n",
    "    pivots = [df1,df2,df3,df4]\n",
    "    pivots_order = sorted(pivots,key=lambda x:x.shape[0])\n",
    "    if set(pivots_order[0]['person_id'].values).issubset(set(pivots_order[3]['person_id'])):\n",
    "        print('the biggest set contains the smallest set')\n",
    "    if set(pivots_order[1]['person_id'].values).issubset(set(pivots_order[3]['person_id'])):\n",
    "        print('the biggest set contains the second smallest set')\n",
    "    if set(pivots_order[2]['person_id'].values).issubset(set(pivots_order[3]['person_id'])):\n",
    "        print('the biggest set contains the third smallest set')\n",
    "    outcome_information = pd.merge(pivots_order[-1].drop('concept_domain',axis=1), \n",
    "                               pivots_order[-2].drop('concept_domain',axis=1),\n",
    "                               how='outer',on=on)\n",
    "    outcome_information = pd.merge(outcome_information, \n",
    "                               pivots_order[-3].drop('concept_domain',axis=1),\n",
    "                               how='outer',on=on)\n",
    "    outcome_information = pd.merge(outcome_information, \n",
    "                               pivots_order[-4].drop('concept_domain',axis=1),\n",
    "                               how='outer',on=on)\n",
    "    return outcome_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure는 median, 나머지는 0으로 결측치 보간\n",
    "def Impute(df,outcome_dict):\n",
    "    drug_concept = outcome_dict['concept_id_drug_list']\n",
    "    cond_concept = outcome_dict['concept_id_cond_list']\n",
    "    proc_concept = outcome_dict['concept_id_proc_list']\n",
    "    meas_concept = outcome_dict['concept_id_meas_list']\n",
    "\n",
    "    impute_median_part = meas_concept\n",
    "    impute_zero_part = drug_concept+cond_concept+proc_concept\n",
    "    \n",
    "    impute_median_part = np.intersect1d(df.columns.tolist(),list(map(int,impute_median_part))).astype(int)\n",
    "    impute_zero_part = np.intersect1d(df.columns.tolist(),list(map(int,impute_zero_part))).astype(int)\n",
    "    df[impute_median_part] = df[impute_median_part].fillna(df[impute_median_part].median())\n",
    "    df[impute_zero_part] = df[impute_zero_part].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(outcome_name, method):\n",
    "    outcome_dict = load_df_and_concept_id(outcome_name, method)\n",
    "    \n",
    "    drug_pivoted = pivot_and_concat(outcome_dict['drug_df'],outcome_dict['concept_id_drug_list'])\n",
    "    cond_pivoted = pivot_and_concat(outcome_dict['cond_df'],outcome_dict['concept_id_cond_list'])\n",
    "    proc_pivoted = pivot_and_concat(outcome_dict['proc_df'],outcome_dict['concept_id_proc_list'])\n",
    "    meas_pivoted = pivot_and_concat(outcome_dict['meas_df'],outcome_dict['concept_id_meas_list'])\n",
    "    \n",
    "    outcome_info = merge_concat(drug_pivoted,cond_pivoted,proc_pivoted,meas_pivoted)\n",
    "    \n",
    "    outcome_info = Impute(outcome_info,outcome_dict)\n",
    "    \n",
    "    return outcome_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dict()\n",
    "for outcome_name in ['Candesartan','Losartan','Olmesartan','Valsartan','Irbesartan',\n",
    "                    'Celecoxib','Acetaminophen','Celecoxib_2','Vancomycin','Naproxen']:\n",
    "    \n",
    "    # 보내드린 폴더의 stage1/input 경로에 맞춰주시면 됩니다.\n",
    "    save_path_train = f'stage1/input/{outcome_name}_{method}_train.csv'\n",
    "    save_path_val = f'stage1/input/{outcome_name}_{method}_val.csv'\n",
    "    df = make_table(outcome_name,method)\n",
    "\n",
    "    columns[outcome_name] = df.columns.tolist()\n",
    "\n",
    "    train, val = train_test_split(df, stratify=df['label'], test_size=0.3, random_state=123)\n",
    "    \n",
    "    train.to_csv(save_path_train,index=False)\n",
    "    val.to_csv(save_path_val,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('columns.pickle','wb') as f:\n",
    "    pickle.dump(columns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('columns.pickle','rb') as f:\n",
    "    konyang_col = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 205  gs  205  k  71  gsk  71\n",
      "211 211  gs  211  k  74  gsk  74\n",
      "114 114  gs  114  k  52  gsk  51\n",
      "232 232  gs  232  k  73  gsk  73\n",
      "99 99  gs  99  k  46  gsk  46\n",
      "177 177  gs  177  k  62  gsk  61\n",
      "363 363  gs  363  k  122  gsk  122\n",
      "189 189  gs  189  k  77  gsk  75\n",
      "424 424  gs  424  k  132  gsk  132\n",
      "317 317  gs  317  k  85  gsk  84\n"
     ]
    }
   ],
   "source": [
    "use_col = dict()\n",
    "for drug,k_col in konyang_col.items():\n",
    "    \n",
    "    gangnam_df = pd.read_csv(f'../2022_WIM_test/stage1/all_drugs_propensity_matching/gangnam/{drug}_gangnam_ExtraTrees_train.csv')\n",
    "    sinchon_df = pd.read_csv(f'../2022_WIM_test/stage1/all_drugs_propensity_matching/sinchon/{drug}_sinchon_ExtraTrees_train.csv')\n",
    "    g_col = gangnam_df.columns.tolist()\n",
    "    s_col = sinchon_df.columns.tolist()\n",
    "    \n",
    "    \n",
    "    gs_col = np.intersect1d(g_col, s_col)\n",
    "    gsk_col = np.intersect1d(gs_col, k_col)\n",
    "\n",
    "    print(len(g_col), len(s_col),' gs ', len(gs_col),' k ', len(k_col),' gsk ', len(gsk_col))\n",
    "    use_col[drug] = list(gsk_col)\n",
    "    \n",
    "#     print(drug,' ' ,len(k_col))\n",
    "#     cond1 = standard['outcome_name']==drug\n",
    "#     cond2 = standard['method'] == 'ExtraTrees'\n",
    "    \n",
    "    \n",
    "    \n",
    "#     temp = 0\n",
    "#     for col in ['common','cond','drug','meas','proc']:\n",
    "#         temp += len(eval(standard[cond1&cond2][col].values[0]))\n",
    "#     print(drug, ' ', temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(use_col).rename('common_columns').to_csv('common_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
